{"cells":[{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql.functions import col"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#Importing data\nspotifyDataList1 = spark.sql(\"SELECT * FROM bigdata1\")\n# spotifyDataList2 = spark.sql(\"SELECT * FROM bigdata2\")\n# spotifyDataList3 = spark.sql(\"SELECT * FROM bigdata3\")\nspotifyDataList = spotifyDataList1\n\n# Adding the rating column \nall_data = spotifyDataList.select(\"trackid\",\"artist_name\",\"track_name\", \"pid\").withColumn(\"rating\", lit(1))"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["all_data.show()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#Adding column songid, which uniqely identifies each song using integers.\n# Takes about ~1 minute\nfrom pyspark.ml.feature import StringIndexer\nstringIndexer = StringIndexer(inputCol=\"trackid\", outputCol=\"songid\", handleInvalid=\"error\", stringOrderType=\"frequencyDesc\")\nmodel = stringIndexer.fit(all_data)\nall_data = model.transform(all_data)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# Exploring the data\nall_data.filter(all_data.trackid == 'spotify:track:5cCAZS9VhLGEDV4NCfieeg').show()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["ratings = all_data.select(\"pid\",\"songid\",\"rating\")"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["#Adding the playlist that we want to continue\n# Songs in the 'Soft Rap' playlist:\n# Khalid - Location\n# Post Malone - Go Flex\n# Post Malone - Too Young\n# Khalid - Saved\n# Post Malone - Congratulations\n# Khalid - Saved\n# Post Malone - Yours Truly, Austin Post\n# 6LACK - PRBLMS\n# Post Malone - I Fall Apart\n# Khalid - Coaster\n# Khalid - Reasons\nsoftRap = spark.createDataFrame([[-1, 9, 1], [-1, 133, 1], [-1, 1228, 1], [-1, 4, 1], [-1, 4876, 1], [-1, 308, 1], [-1, 666, 1], [-1, 1648, 1], [-1, 5437, 1], [-1, 681, 1]], ['pid', 'songid', 'rating'])\nwithMyRatings = softRap.union(ratings)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# Songs in the 'Run the World' playlist:\n# Beyonce - Run the World (Girls) 710.0\n# Rihanna - S&M 1054.0\n# Britney Spears - Work B**ch 2153.0\n# will.i.am - Scream & Shout 1786.0\n# Britney Spears - I Wanna Go 6870.0\nrunTheWorld = spark.createDataFrame([[-2, 710, 1], [-2, 1054, 1], [-2, 2153, 1], [-2, 1786, 1], [-2, 6870, 1]], ['pid', 'songid', 'rating'])\nwithMyRatings = runTheWorld.union(withMyRatings)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["# Splitting training data\nWe will use MLlib's ALS (alternating least squares) to train a ALSModel, which takes a RDD[(user, product, rating)] as an input in Python. ALS has training parameters such as rank for matrix factors and regularization constants. We hold the training, and test sets in memory by calling cache because we need to visit them multiple times."],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\nratingsR = withMyRatings.rdd.map(lambda x: Rating(int(x[0]), int(x[1]), float(x[2])))\ntrain, test = ratingsR.randomSplit([0.7,0.3],7856)\ntrain.cache()\ntest.cache()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#Setting up the parameters for ALS\nrank = 5 # Latent Factors to be made\nnumIterations = 10 # Times to repeat process\n\n#Creating the model on the training data\nmodel = ALS.trainImplicit(train, rank, numIterations)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# Recommendations for 'Soft Rap' playlist\nresult1 = model.recommendProducts(-1,10)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["#Putting results in a Dataframe\nresultSchema = StructType([\n    StructField(\"user\", StringType(), True),\n    StructField(\"product\", IntegerType(), True),\n    StructField(\"rating\", FloatType(), True),\n])\nresultDf = sqlContext.createDataFrame(result1, resultSchema)\nresultDf = resultDf.join(all_data, resultDf.product == all_data.songid).drop_duplicates(['product'])\nresultDf.select('songid', 'artist_name', 'track_name').show()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# Recommendations for 'Run The World' playlist\nresult2 = model.recommendProducts(-2,10)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["resultDf2 = sqlContext.createDataFrame(result2, resultSchema)\nresultDf2 = resultDf2.join(all_data, resultDf2.product == all_data.songid).drop_duplicates(['product'])\nresultDf2.select('songid', 'artist_name', 'track_name').show()"],"metadata":{},"outputs":[],"execution_count":15}],"metadata":{"name":"Spotify-MLib","notebookId":1231404858323794},"nbformat":4,"nbformat_minor":0}
